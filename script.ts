import { Pool } from 'pg';
import Redis from 'ioredis';
import { faker } from '@faker-js/faker';
import * as dotenv from 'dotenv';
import { ChartJSNodeCanvas } from 'chartjs-node-canvas';
import { ChartType } from 'chart.js';
import * as fs from 'fs';

dotenv.config({ path: './.env' });

type Comic = {
  id?: number;
  title: string;
  author: string;
  publisher: string;
  year: number;
  genre: string;
  description: string;
};

// Konfiguracja po≈ÇƒÖczenia PostgreSQL
const postgresPool = new Pool({
  host: process.env.DB_HOST_POSTGRES,
  port: Number(process.env.DB_PORT_POSTGRES),
  user: process.env.DB_USER_POSTGRES,
  password: process.env.DB_PASSWORD_POSTGRES,
  database: process.env.DB_NAME_POSTGRES,
});

// Konfiguracja po≈ÇƒÖczenia Redis
const redisClient = new Redis({
  host: process.env.DB_HOST_REDIS,
  port: Number(process.env.DB_PORT_REDIS),
});

// Czyszczenie danych z baz
const clearDatabases = async () => {
  console.log('üßπ Czyszczenie danych...');

  const client = await postgresPool.connect();

  try {
    await client.query('TRUNCATE TABLE comics RESTART IDENTITY CASCADE');

    console.log('‚úÖ PostgreSQL - wyczyszczony.');
  } catch (error) {
    console.error('‚ùå B≈ÇƒÖd podczas czyszczenia PostgreSQL:', error);
  } finally {
    client.release();
  }

  try {
    await redisClient.flushall();

    console.log('‚úÖ Redis - wyczyszczony.\n');
  } catch (error) {
    console.error('‚ùå B≈ÇƒÖd podczas czyszczenia Redis:', error);
  }
};

const generateDataset = (size: number) => {
  const comics: Comic[] = [];

  for (let i = 0; i < size; i++) {
    comics.push({
      title: faker.lorem.words(3),
      author: faker.person.fullName(),
      publisher: faker.company.name(),
      year: faker.date.past({ years: 50 }).getFullYear(),
      genre: faker.lorem.word(),
      description: faker.lorem.sentence(),
    });
  }

  return comics;
};

// Mierzenie czasu operacji PostgreSQL
const performPostgresOperations = async (dataset: Comic[]): Promise<number[]> => {
  const times: number[] = [];
  
  console.time('PostgreSQL - Create');
  const startCreate = Date.now();

  for (const comic of dataset) {
    const { title, author, publisher, year, genre, description } = comic;

    const client = await postgresPool.connect();

    try {
      await client.query('BEGIN');

      const result = await client.query(
        'INSERT INTO comics (title, author, publisher, year, genre, description) VALUES ($1, $2, $3, $4, $5, $6) RETURNING id',
        [title, author, publisher, year, genre, description]
      );

      comic.id = result.rows[0].id;

      await client.query(
        'INSERT INTO availability (comic_id, available_count) VALUES ($1, $2)',
        [comic.id, faker.number.int({ min: 1, max: 10 })]
      );

      await client.query('COMMIT');
    } catch (error) {

      await client.query('ROLLBACK');

      console.error('Error inserting comic and availability:', error);
    } finally {
      client.release();
    }
  }

  times.push(Date.now() - startCreate);

  console.timeEnd('PostgreSQL - Create');

  console.time('PostgreSQL - Read');

  const startRead = Date.now();

  for (const comic of dataset) {
    const client = await postgresPool.connect();

    await client.query(
      `SELECT comics.*, availability.* 
       FROM comics
       JOIN availability ON comics.id = availability.comic_id
       WHERE comics.title = $1`, 
      [comic.title]
    );    

    await client.query('SELECT * FROM availability WHERE comic_id = $1', [comic.id]);

    client.release();
  }

  times.push(Date.now() - startRead);

  console.timeEnd('PostgreSQL - Read');

  console.time('PostgreSQL - Update');

  const startUpdate = Date.now();

  for (const comic of dataset) {
    const newTitle = faker.lorem.words(2);

    const client = await postgresPool.connect();

    await client.query('UPDATE comics SET title = $1 WHERE title = $2', [newTitle, comic.title]);
    await client.query('UPDATE availability SET available_count = $1 WHERE comic_id = $2', [faker.number.int({ min: 1, max: 10 }), comic.id]);

    client.release();
  }

  times.push(Date.now() - startUpdate);

  console.timeEnd('PostgreSQL - Update');

  console.time('PostgreSQL - Delete');

  const startDelete = Date.now();

  for (const comic of dataset) {
    const client = await postgresPool.connect();

    await client.query('DELETE FROM comics WHERE title = $1', [comic.title]);
    await client.query('DELETE FROM availability WHERE comic_id = $1', [comic.id]);

    client.release();
  }

  times.push(Date.now() - startDelete);

  console.timeEnd('PostgreSQL - Delete');

  console.log('\n');

  return times;
};

// Mierzenie czasu operacji Redis
const performRedisOperations = async (dataset: Comic[]): Promise<number[]> => {
  const times: number[] = [];
  
  console.time('Redis - Create');

  const startCreate = Date.now();

  for (const comic of dataset) {
    const { title, author, publisher, year, genre, description } = comic;

    const comicId = comic.id || faker.number.int();

    await redisClient.hmset(`comic:${comicId}`, {
      id: comicId.toString(),
      title,
      author,
      publisher,
      year: year.toString(),
      genre,
      description,
      created_at: new Date().toISOString(),
    });

    await redisClient.hset(`availability:${comicId}`, 'available_count', faker.number.int({ min: 1, max: 10 }).toString());

    comic.id = comicId;
  }

  times.push(Date.now() - startCreate);

  console.timeEnd('Redis - Create');

  console.time('Redis - Read');

  const startRead = Date.now();

  for (const comic of dataset) {
    await redisClient.hgetall(`comic:${comic.id}`);
    await redisClient.hget(`availability:${comic.id}`, 'available_count');
  }

  times.push(Date.now() - startRead);

  console.timeEnd('Redis - Read');

  console.time('Redis - Update');

  const startUpdate = Date.now();

  for (const comic of dataset) {
    const newTitle = faker.lorem.words(2);

    await redisClient.hset(`comic:${comic.id}`, 'title', newTitle);
    await redisClient.hset(`availability:${comic.id}`, 'available_count', faker.number.int({ min: 1, max: 10 }).toString());
  }

  times.push(Date.now() - startUpdate);

  console.timeEnd('Redis - Update');

  console.time('Redis - Delete');

  const startDelete = Date.now();

  for (const comic of dataset) {
    await redisClient.del(`comic:${comic.id}`);
    await redisClient.del(`availability:${comic.id}`);
  }

  times.push(Date.now() - startDelete);

  console.timeEnd('Redis - Delete');

  return times;
};

const chartJSNodeCanvas = new ChartJSNodeCanvas({ width: 800, height: 600 });

// Generowanie wykres√≥w
const createCharts = async (sizes: number[], pgTimes: number[][], redisTimes: number[][]) => {

  // Generowanie wykres√≥w s≈Çupkowych dla ka≈ºdej wielko≈õci danych
  for (let i = 0; i < sizes.length; i++) {
    const size = sizes[i];

    // Konfiguracja wykresu s≈Çupkowego
    const barChartConfig = {
      type: 'bar' as ChartType,
      data: {
        labels: ['Create', 'Read', 'Update', 'Delete'],
        datasets: [
          {
            label: 'PostgreSQL',
            data: pgTimes[i],
            backgroundColor: 'rgba(54, 162, 235, 0.6)',
          },
          {
            label: 'Redis',
            data: redisTimes[i],
            backgroundColor: 'rgba(255, 99, 132, 0.6)',
          },
        ],
      },
      options: {
        responsive: true,
        plugins: {
          title: {
            display: true,
            text: `Por√≥wnanie czas√≥w operacji CRUD dla ${size} rekord√≥w - Wykres s≈Çupkowy`,
          },
        },
        scales: {
          y: {
            title: {
              display: true,
              text: 'Czas operacji (ms)',
            },
            ticks: {
              callback: function(value) {
                return value + ' ms';
              },
            },
          },
        },
      },
    };

    // Renderowanie wykresu s≈Çupkowego
    const barChartImage = await chartJSNodeCanvas.renderToBuffer(barChartConfig);

    // Zapisanie wykresu s≈Çupkowego
    const barChartPath = `charts/crud_times_${size}_bar.png`;

    fs.writeFileSync(barChartPath, barChartImage);

    console.log(`\n‚úÖ Wykres s≈Çupkowy zapisany: ${barChartPath}`);
  }

  // Konfiguracja wykresu liniowego
  const lineChartConfig = {
    type: 'line' as ChartType,
    data: {
      labels: sizes.map(size => `${size} rekord√≥w`),
      datasets: [
        {
          label: 'PostgreSQL',
          data: pgTimes.map(times => times.reduce((a, b) => a + b) / times.length),
          borderColor: 'rgba(54, 162, 235, 1)',
          fill: false,
          tension: 0.1,
        },
        {
          label: 'Redis',
          data: redisTimes.map(times => times.reduce((a, b) => a + b) / times.length),
          borderColor: 'rgba(255, 99, 132, 1)',
          fill: false,
          tension: 0.1,
        },
      ],
    },
    options: {
      responsive: true,
      plugins: {
        title: {
          display: true,
          text: `Por√≥wnanie czas√≥w operacji CRUD w zale≈ºno≈õci od liczby rekord√≥w`,
        },
      },
      scales: {
        x: {
          title: {
            display: true,
            text: 'Rozmiar zestawu danych (liczba rekord√≥w)',
          },
        },
        y: {
          title: {
            display: true,
            text: 'Czas operacji (ms)',
          },
          ticks: {
            callback: function(value) {
              return value + ' ms';
            },
          },
        },
      },
    },
  };

  // Renderowanie wykresu liniowego
  const lineChartImage = await chartJSNodeCanvas.renderToBuffer(lineChartConfig);

  // Zapisanie wykresu liniowego
  const lineChartPath = `charts/crud_times_comparison_line.png`;

  fs.writeFileSync(lineChartPath, lineChartImage);

  console.log(`\n‚úÖ Wykres liniowy zapisany: ${lineChartPath}`);
};

// Symulacja
const simulate = async () => {
  const datasetSizes = [1000, 10000, 100000];

  fs.mkdirSync('charts', { recursive: true });

  // Przechowuj czasy dla ka≈ºdego rozmiaru zestawu danych
  const pgTimesAll: number[][] = [];

  const redisTimesAll: number[][] = [];

  for (const size of datasetSizes) {
    console.log(`\nüîπ Symulacja dla ${size} rekord√≥w...`);

    await clearDatabases();

    const dataset = generateDataset(size);

    console.log('‚ñ∂Ô∏è PostgreSQL...');

    const pgTimes = await performPostgresOperations(dataset);

    pgTimesAll.push(pgTimes);

    console.log('‚ñ∂Ô∏è Redis...');

    const redisTimes = await performRedisOperations(dataset);

    redisTimesAll.push(redisTimes);
  }

  // Generowanie wykresu por√≥wnania czas√≥w
  await createCharts(datasetSizes, pgTimesAll, redisTimesAll);
};

simulate()
  .then(() => {
    console.log('\n‚úÖ Symulacje zako≈Ñczone!');
    process.exit(0);
  })
  .catch((error) => {
    console.error('‚ùå WystƒÖpi≈Ç b≈ÇƒÖd:', error);
    process.exit(1);
  });
